# For more information, see the Configuration Guide:
# https://www.librechat.ai/docs/configuration/librechat_yaml
 
# Configuration version (required)
version: 1.2.8
 
# Cache settings: Set to true to enable caching
cache: true
 
# Custom interface configuration
interface:
  parameters: false
  sidePanel: true
  prompts: false
  bookmarks: false
  multiConvo: true
  agents: true
  customWelcome: "Hallo {{user.name}}! Willkommen im Chat"
  runCode: true
  webSearch: true
  fileSearch: true
 
# Example Registration Object Structure (optional)
registration:
  # socialLogins: ['github', 'google', 'discord', 'openid', 'facebook']
  allowedDomains:
  - "Student.HTW-Berlin.de"
  - "gmail.com"
 
# rateLimits:
#   fileUploads:
#     ipMax: 100
#     ipWindowInMinutes: 60  # Rate limit window for file uploads per IP
#     userMax: 50
#     userWindowInMinutes: 60  # Rate limit window for file uploads per user
#   conversationsImport:
#     ipMax: 100
#     ipWindowInMinutes: 60  # Rate limit window for conversation imports per IP
#     userMax: 50
#     userWindowInMinutes: 60  # Rate limit window for conversation imports per user

# Web Search
webSearch:
  # Search Provider Configuration
  serperApiKey: "${SERPER_API_KEY}"
  # searxngInstanceUrl: "${SEARXNG_INSTANCE_URL}"
  # searxngApiKey: "${SEARXNG_API_KEY}"
  searchProvider: "serper" # Options: "serper", "searxng"
 
  # Scraper Configuration
  firecrawlApiKey: "${FIRECRAWL_API_KEY}"
  # firecrawlApiUrl: "${FIRECRAWL_API_URL}"
  scraperType: "serper" # Options: "firecrawl", "serper"
 
  # Reranker Configuration
  jinaApiKey: "${JINA_API_KEY}"
  rerankerType: "jina" # Options: "jina", "cohere" 

# Definition of custom endpoints
endpoints:
  # Individual endpoint configurations
  openAI:
    streamRate: 25
    titleModel: "gpt-4o-mini"
    titleMethod: "completion"
    titlePrompt: "Erstelle einen kurzen, präzisen Titel für diese Unterhaltung:\n\n{convo}"

  custom:

    - name: "Perplexity"
      apiKey: "${PERPLEXITY_API_KEY}"
      baseURL: "https://api.perplexity.ai/"
      models:
        default: [
          "sonar-deep-research",
          "sonar-reasoning-pro",
          "sonar-reasoning",
          "sonar-pro",
          "sonar",
          "r1-1776"
          ]
        fetch: false # fetching list of models is not supported
      titleConvo: true
      titleModel: "gpt-4o-mini"
      summarize: false
      summaryModel: "gpt-4o-mini"
      forcePrompt: false
      dropParams: ["stop", "frequency_penalty"]
      modelDisplayLabel: "Perplexity"
 
    # Mistral AI Example
    - name: 'Mistral' # Unique name for the endpoint
      # For `apiKey` and `baseURL`, you can use environment variables that you define.
      # recommended environment variables:
      apiKey: '${MISTRAL_API_KEY}'
      baseURL: 'https://api.mistral.ai/v1'
 
      # Models configuration
      models:
        # List of default models to use. At least one value is required.
        default: ['mistral-tiny', 'mistral-small', 'mistral-medium']
        # Fetch option: Set to true to fetch models from API.
        fetch: true # Defaults to false.
 
      # Optional configurations
 
      # Title Conversation setting
      titleConvo: true # Set to true to enable title conversation
 
      # Title Method: Choose between "completion" or "functions".
      # titleMethod: "completion"  # Defaults to "completion" if omitted.
 
      # Title Model: Specify the model to use for titles.
      titleModel: 'mistral-tiny' # Defaults to "gpt-3.5-turbo" if omitted.
 
      # Summarize setting: Set to true to enable summarization.
      # summarize: false
 
      # Summary Model: Specify the model to use if summarization is enabled.
      # summaryModel: "mistral-tiny"  # Defaults to "gpt-3.5-turbo" if omitted.
 
      # Force Prompt setting: If true, sends a `prompt` parameter instead of `messages`.
      # forcePrompt: false
 
      # The label displayed for the AI model in messages.
      modelDisplayLabel: 'Mistral' # Default is "AI" when not set.
 
      # Add additional parameters to the request. Default params will be overwritten.
      # addParams:
      # safe_prompt: true # This field is specific to Mistral AI: https://docs.mistral.ai/api/
 
      # Drop Default params parameters from the request. See default params in guide linked below.
      # NOTE: For Mistral, it is necessary to drop the following parameters or you will encounter a 422 Error:
      dropParams: ['stop', 'user', 'frequency_penalty', 'presence_penalty']
 
    # OpenRouter
    - name: 'OpenRouter'
      # For `apiKey` and `baseURL`, you can use environment variables that you define.
      # recommended environment variables:
      # Known issue: you should not use `OPENROUTER_API_KEY` as it will then override the `openAI` endpoint to use OpenRouter as well.
      apiKey: '${OPENROUTER_KEY}'
      baseURL: 'https://openrouter.ai/api/v1'
      models:
        default: ['meta-llama/llama-3-70b-instruct']
        fetch: true
      titleConvo: true
      titleModel: 'meta-llama/llama-3-70b-instruct'
      # Recommended: Drop the stop parameter from the request as Openrouter models use a variety of stop tokens.
      dropParams: ['stop']
      modelDisplayLabel: 'OpenRouter'
 
# fileConfig:
#   endpoints:
#     assistants:
#       fileLimit: 5
#       fileSizeLimit: 10  # Maximum size for an individual file in MB
#       totalSizeLimit: 50  # Maximum total size for all files in a single request in MB
#       supportedMimeTypes:
#         - "image/.*"
#         - "application/pdf"
#     openAI:
#       disabled: true  # Disables file uploading to the OpenAI endpoint
#     default:
#       totalSizeLimit: 20
#     YourCustomEndpointName:
#       fileLimit: 2
#       fileSizeLimit: 5
#   serverFileSizeLimit: 100  # Global server file size limit in MB
#   avatarSizeLimit: 2  # Limit for user avatar image size in MB
# See the Custom Configuration Guide for more information:
# https://www.librechat.ai/docs/configuration/librechat_yaml
